# Unified configuration file for managing offline and online models
# Each model is an entry, including name, type, path/API, description, etc.

# ===== Online Model Configurations =====
google/gemini-2.5-flash-preview:
  model_type: online
  api_url: https://openrouter.ai/api/v1/chat/completions
  api_key: "YOUR_API_KEY"
  description: Google Gemini 2.5 Flash Preview online model
  params:
    timeout: 60
    max_retries: 3
    temperature: 0.1
    max_tokens: 4000
  extra_headers:
    HTTP-Referer: https://openrouter.ai/
    X-Title: Slider UI Evaluation

google/gemini-2.5-pro:
  model_type: online
  api_url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent
  api_key: "YOUR_API_KEY"
  description: Google Gemini 2.5 Pro online model
  params:
    timeout: 60
    max_retries: 3
    temperature: 0.1
    max_tokens: 4000

qwen/qwen2.5-vl-72b-instruct:
  model_type: online
  api_url: https://openrouter.ai/api/v1/chat/completions
  api_key: "YOUR_API_KEY"
  description: Qwen 2.5 VL 72B Instruct online model
  params:
    timeout: 60
    max_retries: 3
    temperature: 0.1
    max_tokens: 1000
  extra_headers:
    HTTP-Referer: https://openrouter.ai/
    X-Title: Slider UI Evaluation

anthropic/claude-sonnet-4:
  model_type: online
  api_url: https://api.openrouter.ai/api/v1/chat/completions
  api_key: "YOUR_API_KEY"
  description: Anthropic Claude Sonnet 4 online model
  params:
    timeout: 60
    max_retries: 3
    temperature: 0.1
    max_tokens: 1000
  extra_headers:
    HTTP-Referer: https://openrouter.ai/
    X-Title: Slider UI Evaluation

# ===== Offline Model Configurations =====

GUI-R1-7B:
  model_type: offline
  weights_path: models/GUI-R1-7B/GUI-R1-7B
  description: GUI-R1-7B GUI interaction model
  params:
    max_tokens: 1024
    temperature: 0.1
    do_sample: false
    max_image_pixels: 12845056

Jedi-7B-1080p:
  model_type: offline
  weights_path: models/Jedi-7B-1080p
  description: Jedi-7B-1080p GUI interaction model
  params:
    max_tokens: 1024
    temperature: 0.1
    do_sample: false
    max_image_pixels: 12845056

OS-Atlas-Base-7B:
  model_type: offline
  weights_path: models/OS-Atlas-Base-7B
  description: OS-Atlas-Base-7B GUI action generation model
  params:
    max_tokens: 1024
    temperature: 0.1
    do_sample: false
    max_image_pixels: 1048576

UGround-V1-7B:
  model_type: offline
  weights_path: models/UGround-V1-7B
  description: UGround-V1-7B GUI interaction model
  params:
    max_tokens: 1024
    temperature: 0.1
    do_sample: false
    max_image_pixels: 1048576

# ===== Newly Added Model Configurations =====

# MiniCPMV series model (AgentCPM-GUI)
AgentCPM-GUI:
  model_type: offline
  weights_path: models/AgentCPM-GUI
  description: AgentCPM-GUI GUI interaction model based on MiniCPMV
  params:
    max_tokens: 512
    temperature: 0.1
    do_sample: false
    max_image_pixels: 2048000  # 448*448*4 (max 4 slices)
    # No memory limits - let distributed inference use all available GPU memory

# ChatGLM series model (CogAgent)
cogagent-9b-20241220:
  model_type: offline
  weights_path: models/cogagent-9b-20241220
  description: CogAgent-9B GUI interaction model based on ChatGLM
  client_type: chatglm  # Use specialized ChatGLM client
  params:
    max_tokens: 1024
    temperature: 0.1
    do_sample: false
    max_image_pixels: 1254400  # CogAgent specific: 1120*1120
    use_cache: true  # Enable cache for better performance
    # No memory limits - let distributed inference use all available GPU memory

# LLaVA series model (GUIExplorer)
GUIExplorer:
  model_type: offline
  weights_path: models/GUIExplorer
  description: GUIExplorer GUI interaction model based on LLaVA
  params:
    max_tokens: 512
    temperature: 0.1
    do_sample: false
    max_image_pixels: 1048576  # 1024*1024
    # No memory limits - let distributed inference use all available GPU memory

# Qwen2.5-VL series model (Holo1-7B)
Holo1-7B:
  model_type: offline
  weights_path: models/Holo1-7B
  description: Holo1-7B GUI interaction model based on Qwen2.5-VL
  client_type: ui_r1  # Use specialized UI-R1 client
  params:
    max_tokens: 1024
    temperature: 0.1
    do_sample: false  # Use deterministic generation for consistency
    max_image_pixels: 12845056  # Qwen2.5-VL specific: 14*14*4*1280
    top_k: 50
    top_p: 0.9
    repetition_penalty: 1.05
    use_cache: true
    early_stopping: true

# MobileLlama series model (MobileVLM_V2)
MobileVLM_V2-3B:
  model_type: offline
  weights_path: models/MobileVLM_V2-3B
  description: MobileVLM_V2-3B GUI interaction model based on MobileLlama
  params:
    max_tokens: 1024
    temperature: 0.1
    do_sample: false
    max_image_pixels: 112896  # MobileVLM specific: 336*336 (CLIP style)

MobileVLM_V2-7B:
  model_type: offline
  weights_path: models/MobileVLM_V2-7B
  description: MobileVLM_V2-7B GUI interaction model based on MobileLlama
  params:
    max_tokens: 1024
    temperature: 0.1
    do_sample: false
    max_image_pixels: 112896  # MobileVLM specific: 336*336 (CLIP style)

# Qwen2-VL series model (ShowUI-2B)
ShowUI-2B:
  model_type: offline
  weights_path: models/ShowUI-2B
  description: ShowUI-2B GUI interaction model based on Qwen2-VL
  params:
    max_tokens: 1024
    temperature: 0.1
    do_sample: false
    max_image_pixels: 12845056  # Qwen2-VL specific: 14*14*4*1280

# InternVL2 series model (SpiritSight-Agent-8B)
SpiritSight-Agent-8B:
  model_type: offline
  weights_path: models/SpiritSight-Agent-8B-working
  description: SpiritSight-Agent-8B GUI interaction model based on InternVL2
  params:
    max_tokens: 1024
    temperature: 0.1
    do_sample: false
    max_image_pixels: 200704  # InternVL2 specific: 448*448 (force image size)

# Qwen2.5-VL series model (UI-TARS-1.5-7B)
UI-TARS-1.5-7B:
  model_type: offline
  weights_path: models/UI-TARS-1.5-7B
  description: UI-TARS-1.5-7B GUI interaction model based on Qwen2.5-VL
  client_type: ui_r1  # Use specialized UI-R1 client for Qwen2.5-VL models
  params:
    max_tokens: 1024
    temperature: 0.1
    do_sample: false
    max_image_pixels: 12845056  # Qwen2.5-VL specific: 14*14*4*1280
    use_cache: true
    early_stopping: true
    min_new_tokens: 20  # Ensure sufficient output for coordinate extraction

# LoRA adapter model (web-llama2-13b-adapter)
web-llama2-13b-adapter:
  model_type: offline
  weights_path: models/web-llama2-13b-adapter
  base_model_path: meta-llama/Llama-2-13b-hf
  description: web-llama2-13b-adapter LoRA adapter GUI interaction model based on Llama2-13B
  status: requires_external_dependencies
  notes: "Requires meta-llama/Llama-2-13b-hf base model which is not available locally"
  params:
    max_tokens: 1024
    temperature: 0.1
    do_sample: false
    max_image_pixels: 0  # Text model, does not process images